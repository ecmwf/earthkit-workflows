{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArrayAPI Example of Graph Construction and Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source nodes for the graph are created with the `source` function taking arguments: a function, its args and kwargs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import xarray as xr\n",
    "from cascade.fluent import Fluent\n",
    "\n",
    "args = xr.DataArray([np.fromiter([(2, 3) for _ in range(4)], dtype=object) for _ in range(5)], coords={\"x\": list(range(5)), \"y\": 3*np.array(range(4))})\n",
    "start = Fluent().source(np.random.rand, args)\n",
    "start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the graph now, we will have 20 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cascade.graph.pyvis import to_pyvis\n",
    "\n",
    "net_graph = to_pyvis(start.graph(), notebook=True)\n",
    "net_graph.show(\"start.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the functions such as `mean`, `std`, `min`, `max` etc we can reduce the array of nodes along a specified dimension\n",
    "all the way down to a single node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "single = start.mean(\"x\").min(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our initial payload in creating the source nodes, we chose a random array of shape (2, 3) inside each node. We can use `expand` to expose one of these internal dimensions into the array of nodes. To do this we need specify a new name for the dimension, its size and the axis of the internal array to take values from. After the operation, internally in each node we have arrays of shape (2,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expanded = single.expand(\"z\", 3, 1, 0)\n",
    "expanded.nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can broadcast to match the shape of another existing set of nodes, which in this case creates duplicates of the single existing \n",
    "node along the z dimension. Note, this is an operation purely on the nodes of the graph and no operations are performed to the underlying arrays in each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "single.broadcast(expanded).nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Level Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various low level functions `map`, `reduce`, and `transform` which allow the application of user-defined functions onto the array of nodes. The `map` operation applies a single payload to all nodes, or if a array of payloads is provided of the same shape as the array of nodes, then each node will get a unique payload applied to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cascade.fluent import Payload \n",
    "\n",
    "# Single payload that scales the array in each node by 2\n",
    "expanded.map(Payload(lambda x: x * 2)).nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Or we can scale the array in each node by a different value \n",
    "mapped = expanded.map([Payload(lambda x, a=a: x * a) for a in range(1, 4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arbitrary reduction operations can be applied with the `reduce` operation, which takes arguments `Payload` and the name of the dimension the reduction should be performed along. If no dimension name is supplied, the reduction is performed along the first axis. The higher level functions `mean`, `std`, `min`, `max` are all `reduce` operations with a pre-defined payload.\n",
    "\n",
    "Finally, we have `transform` which allows the shape of the array of nodes in the subsequent action to be changed. The operation takes \n",
    "- a function of the form `func(action: Action, arg: Any) -> Action`\n",
    "- a list of values for `arg` \n",
    "- a name for new dimension along which `arg` varies\n",
    "\n",
    "The resulting nodes will be output of `func` with the different values of `arg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cascade.fluent import Action\n",
    "\n",
    "def _example_transform(action: Action, threshold: float) -> Action:\n",
    "    ret = action.map(Payload(lambda x: x if x > threshold else 0))\n",
    "    ret._add_dimension(\"threshold\", threshold)\n",
    "    return ret\n",
    "\n",
    "mapped.transform(_example_transform, [0, 1, 10], \"threshold\").nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example graph composed by combining the various operations detailed in the Graph Construction section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import xarray as xr\n",
    "from cascade.fluent import Payload, Fluent\n",
    "\n",
    "args = xr.DataArray([np.fromiter([(2, 3) for _ in range(4)], dtype=object) for _ in range(5)], dims=[\"x\", \"y\"])\n",
    "graph = (\n",
    "    Fluent().source(np.random.rand, args)\n",
    "    .mean(\"x\")\n",
    "    .min(\"y\")\n",
    "    .expand(\"z\", 3, 1, 0)\n",
    "    .map([Payload(lambda x, a=a: x * a) for a in range(1, 4)])\n",
    "    .graph()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, the graphs can be executed using with either Dask's dynamic scheduling or a static schedule produced by one of the schedulers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from cascade.executors.dask import DaskLocalExecutor\n",
    "\n",
    "os.environ[\"DASK_LOGGING__DISTRIBUTED\"]=\"debug\"\n",
    "DaskLocalExecutor.execute(graph, memory_limit=\"5GB\", n_workers=1, threads_per_worker=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cascade.executors.dask import DaskLocalExecutor\n",
    "from cascade.schedulers.depthfirst import DepthFirstScheduler\n",
    "from cascade.transformers import to_task_graph\n",
    "from cascade.contextgraph import ContextGraph\n",
    "\n",
    "context = ContextGraph()\n",
    "context.add_node(name=\"cpu1\", type=\"CPU\", speed=10, memory=10)\n",
    "context.add_node(name=\"cpu2\", type=\"CPU\", speed=10, memory=10)\n",
    "context.add_edge(\"cpu1\", \"cpu2\", 10, 1)\n",
    "\n",
    "schedule = DepthFirstScheduler().schedule(to_task_graph(graph, {}), context)\n",
    "DaskLocalExecutor.execute(schedule, memory_limit=\"5GB\", n_workers=1, threads_per_worker=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schedule.task_allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cascade.executors.dask_utils.report import Report\n",
    "\n",
    "report = Report(\"performance_report.html\")\n",
    "report.task_stream.exclude_transfer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cupy Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can construct graphs where cupy arrays instead of numpy arrays are the base objects by changing the input arrays that feature in the payloads of the source method. In this case, we need to add an additional set of tasks to the graph which retrieves the outputs from the GPU so that we can return the results at the end of the execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp \n",
    "import xarray as xr\n",
    "from cascade.fluent import Payload, Fluent\n",
    "\n",
    "args = xr.DataArray([np.fromiter([(2, 3) for _ in range(4)], dtype=object) for _ in range(5)], dims=[\"x\", \"y\"])\n",
    "graph = (\n",
    "    Fluent().source(cp.random.rand, args)\n",
    "    .mean(\"x\")\n",
    "    .min(\"y\")\n",
    "    .expand(\"z\", 3, 1, 0)\n",
    "    .map([Payload(lambda x, a=a: x * a) for a in range(1, 4)])\n",
    "    .map(Payload(lambda x: x.get())) # Move to CPU\n",
    "    .graph()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from cascade.executors.dask import DaskLocalExecutor\n",
    "os.environ[\"DASK_LOGGING__DISTRIBUTED\"]=\"debug\"\n",
    "DaskLocalExecutor.execute(graph, memory_limit=\"5GB\", n_workers=1, threads_per_worker=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
